{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "commodity-price-predictor.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7PkPdbHD2Sg",
        "colab_type": "text"
      },
      "source": [
        "#Time Series Prediction on the Food Commodities Prices in Bandung\n",
        "**Author:** Ferdinand Lanvino<br>\n",
        "**Start Date:** 8th June, 2020<br>\n",
        "**Purpose:** Extract a meaningful information based on prediction model and data analysis of food commoditites<br>\n",
        "**Objective:** Build a prediction model of food commodities prices using various time-series forecasting methods, based on Python.<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcOxMSihPWT9",
        "colab_type": "text"
      },
      "source": [
        "Table of Contents:\n",
        "1. [Q&A](#q&a)\n",
        "2. [Preparing the Project Environment](#preparing-the-project-environment)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7JxYkmWT1H2",
        "colab_type": "text"
      },
      "source": [
        "## 1. Q&A <a name=\"q&a\"></a>\n",
        "**1. What is Time series analysis?**  \n",
        "A. Time Series is a series of observations taken at specified time intervals usually equal intervals. Analysis of the series helps us to predict future values based on previous observed values. In Time series, we have only 2 variables, time & the variable we want to forecast.  \n",
        "\n",
        "  \n",
        "**2. Why & where Time Series is used?**  \n",
        "A. Time series data can be analyzed in order to extract meaningful statistics and other characteristics. It's used in at least the 4 scenarios:  \n",
        "    a) Business Forecasting  \n",
        "    b) Understand past behavior  \n",
        "    c) Plan the future  \n",
        "    d) Evaluate current accomplishment  \n",
        "  \n",
        "**3. When shouldn't we use Time Series Analysis?**  \n",
        "A. We don't need to apply Time series in at least the following 2 cases:  \n",
        "    a) The dependant variable(y) (that is supposed to vary with time) is constant. Eq: y=f(x)=4, a line parallel to x-axis(time) will always remain the same.  \n",
        "    b) The dependant variable(y) represent values that can be denoted as a mathematical function. Eq: sin(x), log(x), Polynomials etc. Thus, we can directly get value at some time using the function itself. No need of forecasting.  \n",
        "  \n",
        "**4. What are the components of Time Series?**  \n",
        "A. There are 4 components:  \n",
        "    a) Trend - Upward & downward movement of the data with time over a large period of time. Eq: Appreciation of Dollar vs rupee.  \n",
        "    b) Seasonality - seasonal variances. Eq: Ice cream sales increases in Summer only  \n",
        "    c) Noise or Irregularity - Spikes & troughs at random intervals  \n",
        "    d) Cyclicity - behavior that repeats itself after large interval of time, like months, years etc.  \n",
        "    \n",
        "**5. What is Stationarity?**    \n",
        "A. Before applying any statistical model on a Time Series, the series has to be stationary, which means that, over different time periods,  \n",
        "    a) It should have constant mean.  \n",
        "    b) It should have constant variance or standard deviation.  \n",
        "    c) Auto-covariance should not depend on time.  \n",
        "\n",
        "Trend & Seasonality are two reasons why a Time Series is not stationary & hence need to be corrected.\n",
        "    \n",
        "**6. Why does Time Series(TS) need to be stationary?**  \n",
        "A. It is because of the following reasons:  \n",
        "    a) If a TS has a particular behavior over a time interval, then there's a high probability that over a different interval, it will have same behavior, provided TS is stationary. This helps in forecasting accurately.  \n",
        "    b) Theories & Mathematical formulas ae more mature & easier to apply for as TS which is stationary.  \n",
        "\n",
        "**7. Tests to check if a series is stationary or not**  \n",
        "A. There are 2 ways to check for Stationarity of a TS:  \n",
        "    a) Rolling Statistics - Plot the moving avg or moving standard deviation to see if it varies with time. Its a visual technique.  \n",
        "    b) ADCF Test - Augmented Dickey–Fuller test is used to gives us various values that can help in identifying stationarity. The Null hypothesis says that a TS is non-stationary. It comprises of a **Test Statistics** & some **critical values** for some confidence levels. If the Test statistics is less than the critical values, we can reject the null hypothesis & say that the series is stationary. THE ADCF test also gives us a **p-value**. Acc to the null hypothesis, lower values of p is better.\n",
        "    \n",
        "**8. What is ARIMA model?**      \n",
        "A. ARIMA(Auto Regressive Integrated Moving Average) is a combination of 2 models AR(Auto Regressive) & MA(Moving Average). It has 3 hyperparameters - P(auto regressive lags),d(order of differentiation),Q(moving avg.) which respectively comes from the AR, I & MA components. The AR part is correlation between prev & current time periods. To smooth out the noise, the MA part is used. The I part binds together the AR & MA parts. \n",
        "\n",
        "**9. How to find value of P & Q for ARIMA ?**  \n",
        "A. We need to take help of ACF(Auto Correlation Function) & PACF(Partial Auto Correlation Function) plots.\n",
        "ACF & PACF graphs are used to find value of P & Q for ARIMA. We need to check, for which value in x-axis, graph line drops to 0 in y-axis for 1st time.  \n",
        "From PACF(at y=0), get P  \n",
        "From ACF(at y=0), get Q  \n",
        "\n",
        "**10. What Is ADCF test?**  \n",
        "A. In statistics and econometrics, an augmented Dickey–Fuller test (ADF) tests the null hypothesis that a unit root is present in a time series sample. The alternative hypothesis is different depending on which version of the test is used, but is usually stationarity or trend-stationarity. It is an augmented version of the Dickey–Fuller test for a larger and more complicated set of time series models.\n",
        "\n",
        "The augmented Dickey–Fuller (ADF) statistic, used in the test, is a negative number. The more negative it is, the stronger the rejection of the hypothesis that there is a unit root at some level of confidence.\n",
        "\n",
        "p value(0<=p<=1) should be as low as possible. Critical values at different confidence intervals should be close to the Test statistics value.\n",
        "\n",
        "**11. What is Exponential Smoothing?**  \n",
        "A. *Exponential smoothing* is a rule of thumb technique for smoothing time series data using the exponential window function. Whereas in the simple moving average the past observations are weighted equally, exponential functions are used to assign exponentially decreasing weights over time. It is an easily learned and easily applied procedure for making some determination based on prior assumptions by the user, such as seasonality. Exponential smoothing is often used for analysis of time-series data.\n",
        "\n",
        "The raw data sequence is often represented by ${x_{t}}$ beginning at time $t=0$, and the output of the exponential smoothing algorithm is commonly written as ${s_{t}}$, which may be regarded as a best estimate of what the next value of $x$ will be. When the sequence of observations begins at time $t=0$, the simplest form of exponential smoothing is given by the formulas:  \n",
        "\n",
        "$s_{0} = x_{0}$  \n",
        "$s_{t} = α*x_{t} + (1-α)*s_{t-1}$  , $t>0$  \n",
        "\n",
        "where $α$ is the smoothing factor, and $0<α<1$.\n",
        "\n",
        "**12. What is Exponential decay?**  \n",
        "A. A quantity is subject to exponential decay if it decreases at a rate proportional to its current value. Symbolically, this process can be expressed by the following differential equation, where N is the quantity and λ (lambda) is a positive rate called the exponential decay constant:\n",
        "\n",
        "$dN/dt = -λN$\n",
        "\n",
        "The solution to this equation (see derivation below) is:  \n",
        "$N(t) = N_{0}*e^{-λt}$  \n",
        "\n",
        "where N(t) is the quantity at time t, and N0 = N(0) is the initial quantity, i.e. the quantity at time t = 0.  \n",
        "\n",
        "**Half Life** is the time required for the decaying quantity to fall to one half of its initial value. It is denoted by $t_{1/2}$. The half-life can be written in terms of the decay constant as:  \n",
        "\n",
        "$t_{1/2} = ln(2)/λ$  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XfeUZznLmnu",
        "colab_type": "text"
      },
      "source": [
        "## 2. Preparing the Project Environment <a name=\"preparing-the-project-environment\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llq432_iG5w0",
        "colab_type": "text"
      },
      "source": [
        "Cloning the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Mq34vX9DuR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "00274b36-68cc-46bb-932b-b437396b260c"
      },
      "source": [
        "# Clone commodity-predictor repo.\n",
        "!git clone -l -s git://github.com/ferdinand-lanvino/commodity-predictor.git\n",
        "%cd commodity-predictor\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'commodity-predictor'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/64)\u001b[K\rremote: Counting objects:   3% (2/64)\u001b[K\rremote: Counting objects:   4% (3/64)\u001b[K\rremote: Counting objects:   6% (4/64)\u001b[K\rremote: Counting objects:   7% (5/64)\u001b[K\rremote: Counting objects:   9% (6/64)\u001b[K\rremote: Counting objects:  10% (7/64)\u001b[K\rremote: Counting objects:  12% (8/64)\u001b[K\rremote: Counting objects:  14% (9/64)\u001b[K\rremote: Counting objects:  15% (10/64)\u001b[K\rremote: Counting objects:  17% (11/64)\u001b[K\rremote: Counting objects:  18% (12/64)\u001b[K\rremote: Counting objects:  20% (13/64)\u001b[K\rremote: Counting objects:  21% (14/64)\u001b[K\rremote: Counting objects:  23% (15/64)\u001b[K\rremote: Counting objects:  25% (16/64)\u001b[K\rremote: Counting objects:  26% (17/64)\u001b[K\rremote: Counting objects:  28% (18/64)\u001b[K\rremote: Counting objects:  29% (19/64)\u001b[K\rremote: Counting objects:  31% (20/64)\u001b[K\rremote: Counting objects:  32% (21/64)\u001b[K\rremote: Counting objects:  34% (22/64)\u001b[K\rremote: Counting objects:  35% (23/64)\u001b[K\rremote: Counting objects:  37% (24/64)\u001b[K\rremote: Counting objects:  39% (25/64)\u001b[K\rremote: Counting objects:  40% (26/64)\u001b[K\rremote: Counting objects:  42% (27/64)\u001b[K\rremote: Counting objects:  43% (28/64)\u001b[K\rremote: Counting objects:  45% (29/64)\u001b[K\rremote: Counting objects:  46% (30/64)\u001b[K\rremote: Counting objects:  48% (31/64)\u001b[K\rremote: Counting objects:  50% (32/64)\u001b[K\rremote: Counting objects:  51% (33/64)\u001b[K\rremote: Counting objects:  53% (34/64)\u001b[K\rremote: Counting objects:  54% (35/64)\u001b[K\rremote: Counting objects:  56% (36/64)\u001b[K\rremote: Counting objects:  57% (37/64)\u001b[K\rremote: Counting objects:  59% (38/64)\u001b[K\rremote: Counting objects:  60% (39/64)\u001b[K\rremote: Counting objects:  62% (40/64)\u001b[K\rremote: Counting objects:  64% (41/64)\u001b[K\rremote: Counting objects:  65% (42/64)\u001b[K\rremote: Counting objects:  67% (43/64)\u001b[K\rremote: Counting objects:  68% (44/64)\u001b[K\rremote: Counting objects:  70% (45/64)\u001b[K\rremote: Counting objects:  71% (46/64)\u001b[K\rremote: Counting objects:  73% (47/64)\u001b[K\rremote: Counting objects:  75% (48/64)\u001b[K\rremote: Counting objects:  76% (49/64)\u001b[K\rremote: Counting objects:  78% (50/64)\u001b[K\rremote: Counting objects:  79% (51/64)\u001b[K\rremote: Counting objects:  81% (52/64)\u001b[K\rremote: Counting objects:  82% (53/64)\u001b[K\rremote: Counting objects:  84% (54/64)\u001b[K\rremote: Counting objects:  85% (55/64)\u001b[K\rremote: Counting objects:  87% (56/64)\u001b[K\rremote: Counting objects:  89% (57/64)\u001b[K\rremote: Counting objects:  90% (58/64)\u001b[K\rremote: Counting objects:  92% (59/64)\u001b[K\rremote: Counting objects:  93% (60/64)\u001b[K\rremote: Counting objects:  95% (61/64)\u001b[K\rremote: Counting objects:  96% (62/64)\u001b[K\rremote: Counting objects:  98% (63/64)\u001b[K\rremote: Counting objects: 100% (64/64)\u001b[K\rremote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/52)\u001b[K\rremote: Compressing objects:   3% (2/52)\u001b[K\rremote: Compressing objects:   5% (3/52)\u001b[K\rremote: Compressing objects:   7% (4/52)\u001b[K\rremote: Compressing objects:   9% (5/52)\u001b[K\rremote: Compressing objects:  11% (6/52)\u001b[K\rremote: Compressing objects:  13% (7/52)\u001b[K\rremote: Compressing objects:  15% (8/52)\u001b[K\rremote: Compressing objects:  17% (9/52)\u001b[K\rremote: Compressing objects:  19% (10/52)\u001b[K\rremote: Compressing objects:  21% (11/52)\u001b[K\rremote: Compressing objects:  23% (12/52)\u001b[K\rremote: Compressing objects:  25% (13/52)\u001b[K\rremote: Compressing objects:  26% (14/52)\u001b[K\rremote: Compressing objects:  28% (15/52)\u001b[K\rremote: Compressing objects:  30% (16/52)\u001b[K\rremote: Compressing objects:  32% (17/52)\u001b[K\rremote: Compressing objects:  34% (18/52)\u001b[K\rremote: Compressing objects:  36% (19/52)\u001b[K\rremote: Compressing objects:  38% (20/52)\u001b[K\rremote: Compressing objects:  40% (21/52)\u001b[K\rremote: Compressing objects:  42% (22/52)\u001b[K\rremote: Compressing objects:  44% (23/52)\u001b[K\rremote: Compressing objects:  46% (24/52)\u001b[K\rremote: Compressing objects:  48% (25/52)\u001b[K\rremote: Compressing objects:  50% (26/52)\u001b[K\rremote: Compressing objects:  51% (27/52)\u001b[K\rremote: Compressing objects:  53% (28/52)\u001b[K\rremote: Compressing objects:  55% (29/52)\u001b[K\rremote: Compressing objects:  57% (30/52)\u001b[K\rremote: Compressing objects:  59% (31/52)\u001b[K\rremote: Compressing objects:  61% (32/52)\u001b[K\rremote: Compressing objects:  63% (33/52)\u001b[K\rremote: Compressing objects:  65% (34/52)\u001b[K\rremote: Compressing objects:  67% (35/52)\u001b[K\rremote: Compressing objects:  69% (36/52)\u001b[K\rremote: Compressing objects:  71% (37/52)\u001b[K\rremote: Compressing objects:  73% (38/52)\u001b[K\rremote: Compressing objects:  75% (39/52)\u001b[K\rremote: Compressing objects:  76% (40/52)\u001b[K\rremote: Compressing objects:  78% (41/52)\u001b[K\rremote: Compressing objects:  80% (42/52)\u001b[K\rremote: Compressing objects:  82% (43/52)\u001b[K\rremote: Compressing objects:  84% (44/52)\u001b[K\rremote: Compressing objects:  86% (45/52)\u001b[K\rremote: Compressing objects:  88% (46/52)\u001b[K\rremote: Compressing objects:  90% (47/52)\u001b[K\rremote: Compressing objects:  92% (48/52)\u001b[K\rremote: Compressing objects:  94% (49/52)\u001b[K\rremote: Compressing objects:  96% (50/52)\u001b[K\rremote: Compressing objects:  98% (51/52)\u001b[K\rremote: Compressing objects: 100% (52/52)\u001b[K\rremote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "Receiving objects:   1% (1/64)   \rReceiving objects:   3% (2/64)   \rReceiving objects:   4% (3/64)   \rReceiving objects:   6% (4/64)   \rReceiving objects:   7% (5/64)   \rReceiving objects:   9% (6/64)   \rReceiving objects:  10% (7/64)   \rReceiving objects:  12% (8/64)   \rReceiving objects:  14% (9/64)   \rReceiving objects:  15% (10/64)   \rReceiving objects:  17% (11/64)   \rReceiving objects:  18% (12/64)   \rReceiving objects:  20% (13/64)   \rReceiving objects:  21% (14/64)   \rReceiving objects:  23% (15/64)   \rReceiving objects:  25% (16/64)   \rReceiving objects:  26% (17/64)   \rReceiving objects:  28% (18/64)   \rReceiving objects:  29% (19/64)   \rReceiving objects:  31% (20/64)   \rReceiving objects:  32% (21/64)   \rReceiving objects:  34% (22/64)   \rReceiving objects:  35% (23/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  37% (24/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  39% (25/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  40% (26/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  42% (27/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  43% (28/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  45% (29/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  46% (30/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  48% (31/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  50% (32/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  51% (33/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  53% (34/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  54% (35/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  56% (36/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  57% (37/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  59% (38/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  60% (39/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  62% (40/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  64% (41/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  65% (42/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  67% (43/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  68% (44/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  70% (45/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  71% (46/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  73% (47/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  75% (48/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  76% (49/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  78% (50/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  79% (51/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  81% (52/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  82% (53/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  84% (54/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  85% (55/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  87% (56/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  89% (57/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  90% (58/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  92% (59/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  93% (60/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  95% (61/64), 188.00 KiB | 343.00 KiB/s   \rremote: Total 64 (delta 19), reused 32 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects:  96% (62/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects:  98% (63/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects: 100% (64/64), 188.00 KiB | 343.00 KiB/s   \rReceiving objects: 100% (64/64), 421.97 KiB | 592.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/19)   \rResolving deltas:  10% (2/19)   \rResolving deltas:  15% (3/19)   \rResolving deltas:  26% (5/19)   \rResolving deltas:  31% (6/19)   \rResolving deltas:  42% (8/19)   \rResolving deltas:  78% (15/19)   \rResolving deltas:  89% (17/19)   \rResolving deltas:  94% (18/19)   \rResolving deltas: 100% (19/19)   \rResolving deltas: 100% (19/19), done.\n",
            "/content/commodity-predictor\n",
            "commodity-price-predictor.ipynb  Dataset  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_dqhGUKj7l",
        "colab_type": "text"
      },
      "source": [
        "Pull the latest update from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NuahaxxKnob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3e26ef08-6574-440a-bda7-969289ba6f72"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating 19e21b7..f7fd8e7\n",
            "Fast-forward\n",
            " Dataset/Unprocessed/combined.csv | 180 \u001b[32m+++++++++++++++++++\u001b[m\u001b[31m--------------------\u001b[m\n",
            " commodity-price-predictor.ipynb  |  33 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 119 insertions(+), 94 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvPTikEKLxtV",
        "colab_type": "text"
      },
      "source": [
        "##2. Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8_d7O3eHBet",
        "colab_type": "text"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpoCi9dtHJb7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "79a52ee7-ead8-48e6-bc30-ea7066d33926"
      },
      "source": [
        "#basic pacakges\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O\n",
        "import datetime # manipulating date formats\n",
        "\n",
        "#visualization\n",
        "import matplotlib as plt # basic plotting\n",
        "import seaborn as sns # for prettier plots\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWQWdkjIpv1",
        "colab_type": "text"
      },
      "source": [
        "Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjKtQRjpIrxH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a41ae975-0704-41d3-e186-a0bd4486c4b9"
      },
      "source": [
        "ds = pd.read_csv('Dataset/Unprocessed/combined.csv')\n",
        "ds"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>komoditas</th>\n",
              "      <th>tanggal</th>\n",
              "      <th>harga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beras</td>\n",
              "      <td>25/07/2016</td>\n",
              "      <td>10900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beras</td>\n",
              "      <td>26/07/2016</td>\n",
              "      <td>10950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beras</td>\n",
              "      <td>27/07/2016</td>\n",
              "      <td>10950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beras</td>\n",
              "      <td>28/07/2016</td>\n",
              "      <td>10950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beras</td>\n",
              "      <td>29/07/2016</td>\n",
              "      <td>10950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26233</th>\n",
              "      <td>Gula Pasir Lokal</td>\n",
              "      <td>23/12/2019</td>\n",
              "      <td>13000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26234</th>\n",
              "      <td>Gula Pasir Lokal</td>\n",
              "      <td>26/12/2019</td>\n",
              "      <td>13000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26235</th>\n",
              "      <td>Gula Pasir Lokal</td>\n",
              "      <td>27/12/2019</td>\n",
              "      <td>13000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26236</th>\n",
              "      <td>Gula Pasir Lokal</td>\n",
              "      <td>30/12/2019</td>\n",
              "      <td>13000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26237</th>\n",
              "      <td>Gula Pasir Lokal</td>\n",
              "      <td>31/12/2019</td>\n",
              "      <td>13000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26238 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              komoditas     tanggal  harga\n",
              "0                 Beras  25/07/2016  10900\n",
              "1                 Beras  26/07/2016  10950\n",
              "2                 Beras  27/07/2016  10950\n",
              "3                 Beras  28/07/2016  10950\n",
              "4                 Beras  29/07/2016  10950\n",
              "...                 ...         ...    ...\n",
              "26233  Gula Pasir Lokal  23/12/2019  13000\n",
              "26234  Gula Pasir Lokal  26/12/2019  13000\n",
              "26235  Gula Pasir Lokal  27/12/2019  13000\n",
              "26236  Gula Pasir Lokal  30/12/2019  13000\n",
              "26237  Gula Pasir Lokal  31/12/2019  13000\n",
              "\n",
              "[26238 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uURB-dJWjlJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "cf8e200b-5f3b-4cce-85e2-591a6f40a79c"
      },
      "source": [
        "#ds.info()\n",
        "ds['tanggal'] = pd.to_datetime(ds['tanggal'],format='%d/%m/%Y') #convert from string to datetime"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6a43ca21e7b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ds.info()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tanggal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tanggal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%d/%m/%Y'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#convert from string to datetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                     result, timezones = array_strptime(\n\u001b[0;32m--> 400\u001b[0;31m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                     )\n\u001b[1;32m    402\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"%Z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: time data 'No.' does not match format '%d/%m/%Y' (match)"
          ]
        }
      ]
    }
  ]
}